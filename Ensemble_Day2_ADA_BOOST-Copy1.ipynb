{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import All the required packages from sklearn\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data in training and testing set \n",
    "X_train, X_test, Y_train, Y_test= model_selection.train_test_split( X, Y, test_size=0.30, random_state=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create random sub sample to train multiple models\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a decision tree classifier\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classification model for bagging\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0 Accuracy is: 1.0\n",
      "Model: 1 Accuracy is: 1.0\n",
      "Model: 2 Accuracy is: 1.0\n",
      "Model: 3 Accuracy is: 0.9090909090909091\n",
      "Model: 4 Accuracy is: 1.0\n",
      "Model: 5 Accuracy is: 1.0\n",
      "Model: 6 Accuracy is: 0.9\n",
      "Model: 7 Accuracy is: 1.0\n",
      "Model: 8 Accuracy is: 1.0\n",
      "Model: 9 Accuracy is: 0.7\n",
      "Mean Accuracy is: 0.9509090909090908\n",
      "accuracy is: 95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "#Train different models and print their accuracy\n",
    "results = model_selection.cross_val_score(model, X_fit, y_fit,cv=kfold)\n",
    "for i in range(len(results)):\n",
    "    print(\"Model: \"+str(i)+\" Accuracy is: \"+str(results[i]))\n",
    "    \n",
    "print(\"Mean Accuracy is: \"+str(results.mean()))\n",
    "\n",
    "model.fit(X_fit, y_fit)\n",
    "pred_label = model.predict(X_eval)\n",
    "nnz = np.shape(y_test)[0] - np.count_nonzero(pred_label - y_test)\n",
    "acc = 100*nnz/np.shape(y_test)[0]\n",
    "print('accuracy is: '+str(acc))\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model KNN: 0 Accuracy is: 1.0\n",
      "Model KNN: 1 Accuracy is: 0.9090909090909091\n",
      "Model KNN: 2 Accuracy is: 0.9090909090909091\n",
      "Model KNN: 3 Accuracy is: 0.9090909090909091\n",
      "Model KNN: 4 Accuracy is: 1.0\n",
      "Model KNN: 5 Accuracy is: 0.9\n",
      "Model KNN: 6 Accuracy is: 0.8\n",
      "Model KNN: 7 Accuracy is: 1.0\n",
      "Model KNN: 8 Accuracy is: 1.0\n",
      "Model KNN: 9 Accuracy is: 1.0\n",
      "Mean Accuracy is: 0.9427272727272727\n",
      "accuracy SVC is: 95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Define a decision tree classifier\n",
    "KNN = KNeighborsClassifier()\n",
    "#base classifier is KNN\n",
    "#Create classification model for bagging\n",
    "model = BaggingClassifier(KNeighborsClassifier(),\n",
    "\t\t\tmax_samples=0.5, max_features=0.5)\n",
    "#0.5 is 50%\n",
    "\n",
    "#Train different models and print their accuracy\n",
    "results = model_selection.cross_val_score(model, X_fit, y_fit,cv=kfold)\n",
    "for i in range(len(results)):\n",
    "    print(\"Model KNN: \"+str(i)+\" Accuracy is: \"+str(results[i]))\n",
    "    \n",
    "print(\"Mean Accuracy is: \"+str(results.mean()))\n",
    "\n",
    "model.fit(X_fit, y_fit)\n",
    "pred_label = model.predict(X_eval)\n",
    "nnz = np.shape(y_test)[0] - np.count_nonzero(pred_label - y_test)\n",
    "acc = 100*nnz/np.shape(y_test)[0]\n",
    "print('accuracy SVC is: '+str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NB: 0 Accuracy is: 1.0\n",
      "Model NB: 1 Accuracy is: 0.8181818181818182\n",
      "Model NB: 2 Accuracy is: 0.9090909090909091\n",
      "Model NB: 3 Accuracy is: 0.8181818181818182\n",
      "Model NB: 4 Accuracy is: 1.0\n",
      "Model NB: 5 Accuracy is: 1.0\n",
      "Model NB: 6 Accuracy is: 0.9\n",
      "Model NB: 7 Accuracy is: 1.0\n",
      "Model NB: 8 Accuracy is: 0.9\n",
      "Model NB: 9 Accuracy is: 0.8\n",
      "Mean Accuracy is: 0.9145454545454547\n",
      "accuracy SVC is: 95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "#Define a decision tree classifier\n",
    "nb = GaussianNB()\n",
    "\n",
    "\n",
    "#Create classification model for bagging\n",
    "model = BaggingClassifier(cart,\n",
    "\t\t\tmax_samples=0.5, max_features=0.5)\n",
    "\n",
    "#Train different models and print their accuracy\n",
    "results = model_selection.cross_val_score(model, X_fit, y_fit,cv=kfold)\n",
    "for i in range(len(results)):\n",
    "    print(\"Model NB: \"+str(i)+\" Accuracy is: \"+str(results[i]))\n",
    "    \n",
    "print(\"Mean Accuracy is: \"+str(results.mean()))\n",
    "\n",
    "model.fit(X_fit, y_fit)\n",
    "pred_label = model.predict(X_eval)\n",
    "nnz = np.shape(y_test)[0] - np.count_nonzero(pred_label - y_test)\n",
    "acc = 100*nnz/np.shape(y_test)[0]\n",
    "print('accuracy SVC is: '+str(acc))\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Logistic: 0 Accuracy is: 1.0\n",
      "Model Logistic: 1 Accuracy is: 1.0\n",
      "Model Logistic: 2 Accuracy is: 0.8181818181818182\n",
      "Model Logistic: 3 Accuracy is: 0.9090909090909091\n",
      "Model Logistic: 4 Accuracy is: 1.0\n",
      "Model Logistic: 5 Accuracy is: 0.9\n",
      "Model Logistic: 6 Accuracy is: 0.9\n",
      "Model Logistic: 7 Accuracy is: 1.0\n",
      "Model Logistic: 8 Accuracy is: 1.0\n",
      "Model Logistic: 9 Accuracy is: 0.9\n",
      "Mean Accuracy is: 0.9427272727272727\n",
      "accuracy SVC is: 97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "#Define a Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "#Create classification model for bagging\n",
    "model = BaggingClassifier(cart,max_samples=0.5, max_features=0.5)\n",
    "\n",
    "#Train different models and print their accuracy\n",
    "results = model_selection.cross_val_score(model, X_fit, y_fit,cv=kfold)\n",
    "for i in range(len(results)):\n",
    "    print(\"Model Logistic: \"+str(i)+\" Accuracy is: \"+str(results[i]))\n",
    "    \n",
    "    \n",
    "print(\"Mean Accuracy is: \"+str(results.mean()))\n",
    "\n",
    "model.fit(X_fit, y_fit)\n",
    "pred_label = model.predict(X_eval)\n",
    "nnz = np.shape(y_test)[0] - np.count_nonzero(pred_label - y_test)\n",
    "acc = 100*nnz/np.shape(y_test)[0]\n",
    "print('accuracy SVC is: '+str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Voting CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VotingClassifier(estimators=[('lr',lr),('nb',nb),('KNN',KNN)],voting='hard')\n",
    "     #weights=[0.3,0.7]\n",
    "    #can ve different models with different parametersnt\n",
    "    \n",
    "    #do fit, predict and confusion matric for model and pri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results=model_selection.cross_val_score(model, X, Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada=AdaBoostClassifier(n_estimators=10)\n",
    "#n_estimators==number of iterations\n",
    "#learning_rate=1\n",
    "model = Ada.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\",accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3047619 , 0.05616791, 0.33336094, 0.01614931, 0.33370025,\n",
       "       0.00177932, 0.33335032, 0.00172832, 0.33344449, 0.00057907])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ada.estimator_errors_  #error for each iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
